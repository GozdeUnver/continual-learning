{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb5ec47-7033-4724-a590-9d1b48963de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af7757f1-1367-4ed8-8a8f-0432fb3b5270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from utils.common import (\n",
    "    m2f_dataset_collate,\n",
    "    m2f_extract_pred_maps_and_masks,\n",
    "    BG_VALUE_255,\n",
    "    set_seed,\n",
    "    pixel_mean_std,\n",
    "    CADIS_PIXEL_MEAN,\n",
    "    CADIS_PIXEL_STD,\n",
    "    CAT1K_PIXEL_MEAN,\n",
    "    CAT1K_PIXEL_STD,\n",
    ")\n",
    "from utils.dataset_utils import (\n",
    "    get_cadisv2_dataset,\n",
    "    get_cataract1k_dataset,\n",
    "    ZEISS_CATEGORIES,\n",
    ")\n",
    "from utils.medical_datasets import Mask2FormerDataset\n",
    "from transformers import (\n",
    "    Mask2FormerForUniversalSegmentation,\n",
    "    SwinModel,\n",
    "    SwinConfig,\n",
    "    Mask2FormerConfig,\n",
    "    AutoImageProcessor,\n",
    "    Mask2FormerImageProcessor\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9423b50c-e565-481c-bd19-3f4d58632e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42) # seed everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a90b3c4f-93f1-469d-997c-dee0316d0110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/venv2/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Matched: hidden_states_norms.stage1.weight != layernorm.weight\n",
      "Not Matched: hidden_states_norms.stage1.bias != layernorm.bias\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(ZEISS_CATEGORIES) - 3  # Remove class incremental\n",
    "SWIN_BACKBONE = \"microsoft/swin-tiny-patch4-window7-224\"#\"microsoft/swin-large-patch4-window12-384\"\n",
    "\n",
    "# Download pretrained swin model\n",
    "swin_model = SwinModel.from_pretrained(\n",
    "    SWIN_BACKBONE, out_features=[\"stage1\", \"stage2\", \"stage3\", \"stage4\"]\n",
    ")\n",
    "swin_config = SwinConfig.from_pretrained(\n",
    "    SWIN_BACKBONE, out_features=[\"stage1\", \"stage2\", \"stage3\", \"stage4\"]\n",
    ")\n",
    "\n",
    "# Create Mask2Former configuration based on Swin's configuration\n",
    "mask2former_config = Mask2FormerConfig(\n",
    "    backbone_config=swin_config, num_labels=NUM_CLASSES #, ignore_value=BG_VALUE\n",
    ")\n",
    "\n",
    "# Create the Mask2Former model with this configuration\n",
    "model = Mask2FormerForUniversalSegmentation(mask2former_config)\n",
    "\n",
    "# Reuse pretrained parameters\n",
    "for swin_param, m2f_param in zip(\n",
    "    swin_model.named_parameters(),\n",
    "    model.model.pixel_level_module.encoder.named_parameters(),\n",
    "):\n",
    "    m2f_param_name = f\"model.pixel_level_module.encoder.{m2f_param[0]}\"\n",
    "\n",
    "    if swin_param[0] == m2f_param[0]:\n",
    "        model.state_dict()[m2f_param_name].copy_(swin_param[1])\n",
    "        continue\n",
    "\n",
    "    print(f\"Not Matched: {m2f_param[0]} != {swin_param[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad8d764d-d90b-4403-98c4-ac0b52148fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/venv2/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f1b0ea9b0e0>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f1b0e8ee600>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f1b0ea99850>}, 'B': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f1b0ea99cd0>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f1b0ea98cb0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f1b0ea98bc0>}}\n"
     ]
    }
   ],
   "source": [
    "# Helper function to load datasets\n",
    "def load_dataset(dataset_getter, data_path, domain_incremental):\n",
    "    return dataset_getter(data_path, domain_incremental=domain_incremental)\n",
    "\n",
    "\n",
    "# Helper function to create dataloaders for a dataset\n",
    "def create_dataloaders(\n",
    "    dataset, batch_size, shuffle, num_workers, drop_last, pin_memory, collate_fn\n",
    "):\n",
    "    return {\n",
    "        \"train\": DataLoader(\n",
    "            dataset[\"train\"],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=drop_last,\n",
    "            pin_memory=pin_memory,\n",
    "            collate_fn=collate_fn,\n",
    "        ),\n",
    "        \"val\": DataLoader(\n",
    "            dataset[\"val\"],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=drop_last,\n",
    "            pin_memory=pin_memory,\n",
    "            collate_fn=collate_fn,\n",
    "        ),\n",
    "        \"test\": DataLoader(\n",
    "            dataset[\"test\"],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=drop_last,\n",
    "            pin_memory=pin_memory,\n",
    "            collate_fn=collate_fn,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "datasets = {\n",
    "    \"A\": load_dataset(get_cadisv2_dataset, \"../../storage/data/CaDISv2\", True),\n",
    "    \"B\": load_dataset(get_cataract1k_dataset, \"../../storage/data/cataract-1k\", True),\n",
    "}\n",
    "\n",
    "# pixel_mean_A,pixel_std_A=pixel_mean_std(datasets[\"A\"][0])\n",
    "pixel_mean_A = CADIS_PIXEL_MEAN\n",
    "pixel_std_A = CADIS_PIXEL_STD\n",
    "\n",
    "# pixel_mean_B,pixel_std_B=pixel_mean_std(datasets[\"B\"][0])\n",
    "pixel_mean_B = CAT1K_PIXEL_MEAN\n",
    "pixel_std_B = CAT1K_PIXEL_STD\n",
    "\n",
    "# Define preprocessor\n",
    "swin_processor = AutoImageProcessor.from_pretrained(SWIN_BACKBONE)\n",
    "m2f_preprocessor_A = Mask2FormerImageProcessor(\n",
    "    reduce_labels=True,\n",
    "    ignore_index=255,\n",
    "    do_resize=False,\n",
    "    do_rescale=True,\n",
    "    do_normalize=True,\n",
    "    image_std=pixel_std_A,\n",
    "    image_mean=pixel_mean_A,\n",
    ")\n",
    "\n",
    "m2f_preprocessor_B = Mask2FormerImageProcessor(\n",
    "    reduce_labels=True,\n",
    "    ignore_index=255,\n",
    "    do_resize=False,\n",
    "    do_rescale=True,\n",
    "    do_normalize=True,\n",
    "    image_std=pixel_std_B,\n",
    "    image_mean=pixel_mean_B,\n",
    ")\n",
    "\n",
    "# Create Mask2Former Datasets\n",
    "m2f_datasets = {\n",
    "    \"A\": {\n",
    "        \"train\": Mask2FormerDataset(datasets[\"A\"][0], m2f_preprocessor_A),\n",
    "        \"val\": Mask2FormerDataset(datasets[\"A\"][1], m2f_preprocessor_A),\n",
    "        \"test\": Mask2FormerDataset(datasets[\"A\"][2], m2f_preprocessor_A),\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"train\": Mask2FormerDataset(datasets[\"B\"][0], m2f_preprocessor_B),\n",
    "        \"val\": Mask2FormerDataset(datasets[\"B\"][1], m2f_preprocessor_B),\n",
    "        \"test\": Mask2FormerDataset(datasets[\"B\"][2], m2f_preprocessor_B),\n",
    "    },\n",
    "}\n",
    "\n",
    "# DataLoader parameters\n",
    "N_WORKERS = 4\n",
    "BATCH_SIZE = 16\n",
    "SHUFFLE = True\n",
    "DROP_LAST = True\n",
    "\n",
    "dataloader_params = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"shuffle\": SHUFFLE,\n",
    "    \"num_workers\": N_WORKERS,\n",
    "    \"drop_last\": DROP_LAST,\n",
    "    \"pin_memory\": True,\n",
    "    \"collate_fn\": m2f_dataset_collate,\n",
    "}\n",
    "\n",
    "# Create DataLoaders\n",
    "dataloaders = {\n",
    "    key: create_dataloaders(m2f_datasets[key], **dataloader_params)\n",
    "    for key in m2f_datasets\n",
    "}\n",
    "\n",
    "print(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3ba9e5-e5f5-4be0-94ab-2ed1927da0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ebe029e-cfa5-4339-84fe-aed389d9cfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1178), started 0:17:01 ago. (Use '!kill 1178' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensorboard setup\n",
    "out_dir=\"outputs/\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "if not os.path.exists(out_dir+\"runs\"):\n",
    "    os.makedirs(out_dir+\"runs\")\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir outputs/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e0fe423-3459-49c1-85c0-4b6ccb243b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deb16789-f95a-46a1-8f59-90591648ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "NUM_EPOCHS = 200\n",
    "LEARNING_RATE = 1e-4\n",
    "LR_MULTIPLIER = 0.1\n",
    "BACKBONE_LR = LEARNING_RATE * LR_MULTIPLIER\n",
    "WEIGHT_DECAY = 0.05\n",
    "PATIENCE=15\n",
    "metric = evaluate.load(\"mean_iou\") # mIoU will be used to pick the best performing model using val set\n",
    "encoder_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.pixel_level_module.encoder\")\n",
    "]\n",
    "decoder_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.pixel_level_module.decoder\")\n",
    "]\n",
    "transformer_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.transformer_module\")\n",
    "]\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": encoder_params, \"lr\": BACKBONE_LR},\n",
    "        {\"params\": decoder_params},\n",
    "        {\"params\": transformer_params},\n",
    "    ],\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.PolynomialLR(\n",
    "    optimizer, total_iters=NUM_EPOCHS, power=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0531da3-3c98-4a89-922c-113dc1ce1786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mge85ket\u001b[0m (\u001b[33mcontinual-learning-tum\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WandB for team usage !!!!\n",
    "\n",
    "wandb.login() # use this one if a different person is going to run the notebook\n",
    "#wandb.login(relogin=False) # if the same person in the last run is going to run the notebook again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0158e0bb-458e-4ca7-894c-d7445dc5472c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/continual-learning/wandb/run-20240522_193014-4t3o52ol</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/4t3o52ol' target=\"_blank\">M2F-Swin-Tiny-Train_Cataract1k</a></strong> to <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/4t3o52ol' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original/runs/4t3o52ol</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/continual-learning-tum/M2F_original/runs/4t3o52ol?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f1b098309e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"M2F_original\",\n",
    "    config={\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"learning_rate_multiplier\": LR_MULTIPLIER,\n",
    "        \"backbone_learning_rate\": BACKBONE_LR,\n",
    "        \"learning_rate_scheduler\": scheduler.__class__.__name__,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"backbone\": SWIN_BACKBONE,\n",
    "        \"m2f_preprocessor\": m2f_preprocessor_B.__dict__,\n",
    "        \"m2f_model_config\": model.config\n",
    "    },\n",
    "    name=\"M2F-Swin-Tiny-Train_Cataract1k\",\n",
    "    notes=\"M2F with tiny Swin backbone pretrained on ImageNet-1K. \\\n",
    "        Scenario: Train on B, Test on B\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "290bd32f-5e7c-43f6-b598-d67228b9b217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store best model weights in:  outputs/models/m2f_swin_backbone_train_cataract1k/best_model/\n",
      "Store final model weights in:  outputs/models/m2f_swin_backbone_train_cataract1k/final_model/\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard logging\n",
    "writer = SummaryWriter(log_dir=out_dir + \"runs\")\n",
    "\n",
    "# Model checkpointing\n",
    "base_model_name=\"m2f_swin_backbone_train_cataract1k\"\n",
    "model_dir = out_dir + \"models/\"\n",
    "if not os.path.exists(model_dir):\n",
    "    print(\"Store weights in: \", model_dir)\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "best_model_dir = model_dir + f\"{base_model_name}/best_model/\"\n",
    "if not os.path.exists(best_model_dir):\n",
    "    print(\"Store best model weights in: \", best_model_dir)\n",
    "    os.makedirs(best_model_dir)\n",
    "final_model_dir = model_dir + f\"{base_model_name}/final_model/\"\n",
    "if not os.path.exists(final_model_dir):\n",
    "    print(\"Store final model weights in: \", final_model_dir)\n",
    "    os.makedirs(final_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efd2c0a9-d7ad-44cb-8022-dd7d5764a615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/models/m2f_swin_backbone_train_cataract1k/preprocessor_config.json']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the preprocessor\n",
    "m2f_preprocessor_B.save_pretrained(model_dir + base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b436052-9f34-403d-8059-0dffbf1d96e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 Training: 100%|██████████| 112/112 [04:02<00:00,  2.16s/it, loss=1005.3492]\n",
      "Epoch 1/200 Validation: 100%|██████████| 14/14 [00:28<00:00,  2.06s/it, loss=1034.2212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 75.5773, Train mIoU: 0.0561, Validation Loss: 63.7610, Validation mIoU: 0.0527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200 Training: 100%|██████████| 112/112 [04:25<00:00,  2.37s/it, loss=456.7245]\n",
      "Epoch 2/200 Validation: 100%|██████████| 14/14 [00:29<00:00,  2.08s/it, loss=443.1598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 46.6233, Train mIoU: 0.1180, Validation Loss: 29.6270, Validation mIoU: 0.2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200 Training: 100%|██████████| 112/112 [04:39<00:00,  2.49s/it, loss=277.5189]\n",
      "Epoch 3/200 Validation: 100%|██████████| 14/14 [00:26<00:00,  1.86s/it, loss=312.1281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 24.7570, Train mIoU: 0.2643, Validation Loss: 17.9317, Validation mIoU: 0.3077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200 Training: 100%|██████████| 112/112 [04:43<00:00,  2.53s/it, loss=218.5298]\n",
      "Epoch 4/200 Validation: 100%|██████████| 14/14 [00:24<00:00,  1.73s/it, loss=213.4838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss: 16.5261, Train mIoU: 0.3603, Validation Loss: 14.5305, Validation mIoU: 0.4005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200 Training: 100%|██████████| 112/112 [04:23<00:00,  2.35s/it, loss=283.2661]\n",
      "Epoch 5/200 Validation: 100%|██████████| 14/14 [00:26<00:00,  1.90s/it, loss=207.1202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Train Loss: 13.9841, Train mIoU: 0.4384, Validation Loss: 14.2592, Validation mIoU: 0.4985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200 Training: 100%|██████████| 112/112 [04:32<00:00,  2.43s/it, loss=170.4574]\n",
      "Epoch 6/200 Validation: 100%|██████████| 14/14 [00:23<00:00,  1.71s/it, loss=160.7390]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 12.7808, Train mIoU: 0.5229, Validation Loss: 11.9468, Validation mIoU: 0.5536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200 Training: 100%|██████████| 112/112 [04:22<00:00,  2.34s/it, loss=178.7817]\n",
      "Epoch 7/200 Validation: 100%|██████████| 14/14 [00:21<00:00,  1.52s/it, loss=195.4693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 11.5162, Train mIoU: 0.6232, Validation Loss: 11.8902, Validation mIoU: 0.6239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200 Training: 100%|██████████| 112/112 [04:51<00:00,  2.60s/it, loss=151.7322]\n",
      "Epoch 8/200 Validation: 100%|██████████| 14/14 [00:25<00:00,  1.82s/it, loss=169.8750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Train Loss: 10.9962, Train mIoU: 0.6969, Validation Loss: 10.9025, Validation mIoU: 0.6095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200 Training: 100%|██████████| 112/112 [04:55<00:00,  2.64s/it, loss=200.2686]\n",
      "Epoch 9/200 Validation: 100%|██████████| 14/14 [00:25<00:00,  1.81s/it, loss=144.3062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Train Loss: 10.0828, Train mIoU: 0.7432, Validation Loss: 10.1736, Validation mIoU: 0.8034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200 Training: 100%|██████████| 112/112 [03:54<00:00,  2.09s/it, loss=141.2014]\n",
      "Epoch 10/200 Validation: 100%|██████████| 14/14 [00:22<00:00,  1.61s/it, loss=186.5227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Train Loss: 9.3311, Train mIoU: 0.8310, Validation Loss: 9.4750, Validation mIoU: 0.8526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200 Training: 100%|██████████| 112/112 [04:34<00:00,  2.45s/it, loss=136.5857]\n",
      "Epoch 11/200 Validation: 100%|██████████| 14/14 [00:21<00:00,  1.55s/it, loss=159.2937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200, Train Loss: 8.7547, Train mIoU: 0.8564, Validation Loss: 9.4845, Validation mIoU: 0.7024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200 Training: 100%|██████████| 112/112 [03:55<00:00,  2.11s/it, loss=119.9671]\n",
      "Epoch 12/200 Validation: 100%|██████████| 14/14 [00:29<00:00,  2.13s/it, loss=170.6537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200, Train Loss: 8.1992, Train mIoU: 0.8753, Validation Loss: 9.3101, Validation mIoU: 0.8035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200 Training: 100%|██████████| 112/112 [04:34<00:00,  2.45s/it, loss=145.1824]\n",
      "Epoch 13/200 Validation: 100%|██████████| 14/14 [00:29<00:00,  2.12s/it, loss=130.2578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200, Train Loss: 7.9346, Train mIoU: 0.8984, Validation Loss: 9.0380, Validation mIoU: 0.8238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200 Training: 100%|██████████| 112/112 [04:19<00:00,  2.32s/it, loss=129.4955]\n",
      "Epoch 14/200 Validation: 100%|██████████| 14/14 [00:26<00:00,  1.87s/it, loss=129.5777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200, Train Loss: 7.9298, Train mIoU: 0.8975, Validation Loss: 8.9417, Validation mIoU: 0.7770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200 Training: 100%|██████████| 112/112 [04:27<00:00,  2.39s/it, loss=116.6620]\n",
      "Epoch 15/200 Validation: 100%|██████████| 14/14 [00:28<00:00,  2.07s/it, loss=141.9222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200, Train Loss: 7.5682, Train mIoU: 0.9167, Validation Loss: 8.7759, Validation mIoU: 0.8661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200 Training: 100%|██████████| 112/112 [04:26<00:00,  2.38s/it, loss=107.9743]\n",
      "Epoch 16/200 Validation: 100%|██████████| 14/14 [00:26<00:00,  1.90s/it, loss=116.5517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200, Train Loss: 7.3831, Train mIoU: 0.9232, Validation Loss: 8.4447, Validation mIoU: 0.8371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200 Training: 100%|██████████| 112/112 [04:22<00:00,  2.34s/it, loss=119.3054]\n",
      "Epoch 17/200 Validation: 100%|██████████| 14/14 [00:25<00:00,  1.80s/it, loss=124.5542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200, Train Loss: 7.3554, Train mIoU: 0.9141, Validation Loss: 8.1975, Validation mIoU: 0.8541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200 Training: 100%|██████████| 112/112 [04:09<00:00,  2.23s/it, loss=116.9357]\n",
      "Epoch 18/200 Validation: 100%|██████████| 14/14 [00:25<00:00,  1.84s/it, loss=150.1043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200, Train Loss: 7.0820, Train mIoU: 0.9208, Validation Loss: 8.5689, Validation mIoU: 0.7813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200 Training: 100%|██████████| 112/112 [04:07<00:00,  2.21s/it, loss=98.2649] \n",
      "Epoch 19/200 Validation: 100%|██████████| 14/14 [00:23<00:00,  1.68s/it, loss=187.2308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200, Train Loss: 6.7037, Train mIoU: 0.9393, Validation Loss: 8.1149, Validation mIoU: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200 Training: 100%|██████████| 112/112 [04:31<00:00,  2.42s/it, loss=123.9750]\n",
      "Epoch 20/200 Validation: 100%|██████████| 14/14 [00:28<00:00,  2.07s/it, loss=142.1499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Train Loss: 8.1609, Train mIoU: 0.8820, Validation Loss: 9.6510, Validation mIoU: 0.6926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200 Training: 100%|██████████| 112/112 [04:12<00:00,  2.25s/it, loss=109.7539]\n",
      "Epoch 21/200 Validation: 100%|██████████| 14/14 [00:22<00:00,  1.62s/it, loss=136.8968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200, Train Loss: 7.2986, Train mIoU: 0.8841, Validation Loss: 8.9689, Validation mIoU: 0.8472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/200 Training: 100%|██████████| 112/112 [04:05<00:00,  2.20s/it, loss=99.6331] \n",
      "Epoch 22/200 Validation: 100%|██████████| 14/14 [00:26<00:00,  1.90s/it, loss=116.2064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200, Train Loss: 7.1549, Train mIoU: 0.9162, Validation Loss: 8.5157, Validation mIoU: 0.8304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/200 Training: 100%|██████████| 112/112 [04:08<00:00,  2.21s/it, loss=87.9806] \n",
      "Epoch 23/200 Validation: 100%|██████████| 14/14 [00:19<00:00,  1.39s/it, loss=112.4945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200, Train Loss: 6.6452, Train mIoU: 0.9170, Validation Loss: 8.2561, Validation mIoU: 0.8683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/200 Training: 100%|██████████| 112/112 [04:00<00:00,  2.15s/it, loss=95.3512] \n",
      "Epoch 24/200 Validation: 100%|██████████| 14/14 [00:26<00:00,  1.88s/it, loss=169.1621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200, Train Loss: 6.4900, Train mIoU: 0.9452, Validation Loss: 7.9266, Validation mIoU: 0.7951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/200 Training: 100%|██████████| 112/112 [04:11<00:00,  2.24s/it, loss=85.4631] \n",
      "Epoch 25/200 Validation: 100%|██████████| 14/14 [00:26<00:00,  1.88s/it, loss=110.5565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200, Train Loss: 6.0841, Train mIoU: 0.9402, Validation Loss: 8.7427, Validation mIoU: 0.8370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200 Training: 100%|██████████| 112/112 [04:09<00:00,  2.23s/it, loss=87.2481] \n",
      "Epoch 26/200 Validation: 100%|██████████| 14/14 [00:27<00:00,  1.94s/it, loss=135.7147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200, Train Loss: 6.0309, Train mIoU: 0.9389, Validation Loss: 7.8734, Validation mIoU: 0.7716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/200 Training: 100%|██████████| 112/112 [04:06<00:00,  2.20s/it, loss=88.2843] \n",
      "Epoch 27/200 Validation: 100%|██████████| 14/14 [00:23<00:00,  1.67s/it, loss=110.0062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200, Train Loss: 5.8112, Train mIoU: 0.9520, Validation Loss: 8.2624, Validation mIoU: 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/200 Training: 100%|██████████| 112/112 [03:54<00:00,  2.10s/it, loss=91.4766] \n",
      "Epoch 28/200 Validation: 100%|██████████| 14/14 [00:11<00:00,  1.24it/s, loss=117.9502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Train Loss: 6.6771, Train mIoU: 0.9198, Validation Loss: 8.4984, Validation mIoU: 0.7635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/200 Training: 100%|██████████| 112/112 [02:14<00:00,  1.20s/it, loss=93.8823] \n",
      "Epoch 29/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.29it/s, loss=130.0483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200, Train Loss: 6.0221, Train mIoU: 0.9423, Validation Loss: 7.9589, Validation mIoU: 0.8411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/200 Training: 100%|██████████| 112/112 [02:17<00:00,  1.23s/it, loss=98.7947] \n",
      "Epoch 30/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.28it/s, loss=114.3894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Train Loss: 6.2123, Train mIoU: 0.9379, Validation Loss: 8.1811, Validation mIoU: 0.8171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200 Training: 100%|██████████| 112/112 [02:11<00:00,  1.18s/it, loss=88.5705] \n",
      "Epoch 31/200 Validation: 100%|██████████| 14/14 [00:15<00:00,  1.10s/it, loss=138.6827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200, Train Loss: 5.8942, Train mIoU: 0.9560, Validation Loss: 8.0357, Validation mIoU: 0.8632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/200 Training: 100%|██████████| 112/112 [02:23<00:00,  1.28s/it, loss=83.5863] \n",
      "Epoch 32/200 Validation: 100%|██████████| 14/14 [00:11<00:00,  1.20it/s, loss=120.5308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200, Train Loss: 5.6216, Train mIoU: 0.9588, Validation Loss: 8.3198, Validation mIoU: 0.8461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/200 Training: 100%|██████████| 112/112 [02:19<00:00,  1.25s/it, loss=96.4502] \n",
      "Epoch 33/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, loss=121.3018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200, Train Loss: 5.5729, Train mIoU: 0.9611, Validation Loss: 7.5850, Validation mIoU: 0.7510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/200 Training: 100%|██████████| 112/112 [02:35<00:00,  1.39s/it, loss=81.9006] \n",
      "Epoch 34/200 Validation: 100%|██████████| 14/14 [00:12<00:00,  1.11it/s, loss=119.7700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200, Train Loss: 5.6075, Train mIoU: 0.9600, Validation Loss: 7.7490, Validation mIoU: 0.7654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/200 Training: 100%|██████████| 112/112 [02:50<00:00,  1.52s/it, loss=78.6634]\n",
      "Epoch 35/200 Validation: 100%|██████████| 14/14 [00:12<00:00,  1.14it/s, loss=91.7693] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200, Train Loss: 5.4461, Train mIoU: 0.9625, Validation Loss: 7.8459, Validation mIoU: 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/200 Training: 100%|██████████| 112/112 [02:18<00:00,  1.24s/it, loss=90.4501] \n",
      "Epoch 36/200 Validation: 100%|██████████| 14/14 [00:13<00:00,  1.02it/s, loss=108.9191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200, Train Loss: 5.4865, Train mIoU: 0.9573, Validation Loss: 8.5012, Validation mIoU: 0.7426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/200 Training: 100%|██████████| 112/112 [02:14<00:00,  1.20s/it, loss=79.4322]\n",
      "Epoch 37/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.32it/s, loss=121.0195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200, Train Loss: 5.5642, Train mIoU: 0.9447, Validation Loss: 8.6511, Validation mIoU: 0.7469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/200 Training: 100%|██████████| 112/112 [02:52<00:00,  1.54s/it, loss=89.8768]\n",
      "Epoch 38/200 Validation: 100%|██████████| 14/14 [00:11<00:00,  1.17it/s, loss=104.0121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200, Train Loss: 5.3639, Train mIoU: 0.9612, Validation Loss: 8.1783, Validation mIoU: 0.7978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/200 Training: 100%|██████████| 112/112 [02:13<00:00,  1.20s/it, loss=87.4207] \n",
      "Epoch 39/200 Validation: 100%|██████████| 14/14 [00:15<00:00,  1.12s/it, loss=124.7681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200, Train Loss: 5.2418, Train mIoU: 0.9542, Validation Loss: 7.9088, Validation mIoU: 0.8776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/200 Training: 100%|██████████| 112/112 [02:19<00:00,  1.25s/it, loss=84.8645] \n",
      "Epoch 40/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.35it/s, loss=133.7952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Train Loss: 5.6825, Train mIoU: 0.9587, Validation Loss: 8.5264, Validation mIoU: 0.7715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/200 Training: 100%|██████████| 112/112 [02:23<00:00,  1.28s/it, loss=79.3472]\n",
      "Epoch 41/200 Validation: 100%|██████████| 14/14 [00:12<00:00,  1.15it/s, loss=137.8056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200, Train Loss: 5.3715, Train mIoU: 0.9617, Validation Loss: 7.8416, Validation mIoU: 0.7692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/200 Training: 100%|██████████| 112/112 [02:21<00:00,  1.27s/it, loss=70.9277]\n",
      "Epoch 42/200 Validation: 100%|██████████| 14/14 [00:12<00:00,  1.16it/s, loss=108.0276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200, Train Loss: 5.2162, Train mIoU: 0.9647, Validation Loss: 7.8950, Validation mIoU: 0.8257\n",
      "Early stopping at epoch 41\n"
     ]
    }
   ],
   "source": [
    "# To avoid making stupid errors\n",
    "CURR_TASK = \"B\"\n",
    "\n",
    "# For storing the model\n",
    "best_val_metric = -np.inf\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "counter=0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    # Set up tqdm for the training loop\n",
    "    train_loader = tqdm(\n",
    "        dataloaders[CURR_TASK][\"train\"], desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS} Training\"\n",
    "    )\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Compute gradient and perform step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        train_running_loss += current_loss\n",
    "        train_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor_B\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "    # After compute the batches that were added are deleted\n",
    "    mean_train_iou = metric.compute(\n",
    "        num_labels=NUM_CLASSES, ignore_index=BG_VALUE_255, reduce_labels=False\n",
    "    )[\"mean_iou\"]\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loader = tqdm(\n",
    "        dataloaders[CURR_TASK][\"val\"], desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS} Validation\"\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            # Move everything to the device\n",
    "            batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "            batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "            batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "            batch[\"class_labels\"] = [\n",
    "                entry.to(device) for entry in batch[\"class_labels\"]\n",
    "            ]\n",
    "            # Compute output and loss\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            # Record losses\n",
    "            current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "            val_running_loss += current_loss\n",
    "            val_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "            # Extract and compute metrics\n",
    "            pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "                batch, outputs, m2f_preprocessor_B\n",
    "            )\n",
    "            metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "    # After compute the batches that were added are deleted\n",
    "    mean_val_iou = metric.compute(\n",
    "        num_labels=NUM_CLASSES, ignore_index=BG_VALUE_255, reduce_labels=False\n",
    "    )[\"mean_iou\"]\n",
    "\n",
    "    epoch_train_loss = train_running_loss / len(dataloaders[CURR_TASK][\"train\"].dataset)\n",
    "    epoch_val_loss = val_running_loss / len(dataloaders[CURR_TASK][\"val\"].dataset)\n",
    "\n",
    "    writer.add_scalar(f\"Loss/train_{base_model_name}_{CURR_TASK}\", epoch_train_loss, epoch + 1)\n",
    "    writer.add_scalar(f\"Loss/val_{base_model_name}_{CURR_TASK}\", epoch_val_loss, epoch + 1)\n",
    "    writer.add_scalar(f\"mIoU/train_{base_model_name}_{CURR_TASK}\", mean_train_iou, epoch + 1)\n",
    "    writer.add_scalar(f\"mIoU/val_{base_model_name}_{CURR_TASK}\", mean_val_iou, epoch + 1)\n",
    "\n",
    "    wandb.log({\n",
    "        f\"Loss/train_{CURR_TASK}\": epoch_train_loss,\n",
    "        f\"Loss/val_{CURR_TASK}\": epoch_val_loss,\n",
    "        f\"mIoU/train_{CURR_TASK}\": mean_train_iou,\n",
    "        f\"mIoU/val_{CURR_TASK}\": mean_val_iou\n",
    "    })\n",
    "\n",
    "\n",
    "    tqdm.write(\n",
    "        f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Train Loss: {epoch_train_loss:.4f}, Train mIoU: {mean_train_iou:.4f}, Validation Loss: {epoch_val_loss:.4f}, Validation mIoU: {mean_val_iou:.4f}\"\n",
    "    )\n",
    "    if mean_val_iou > best_val_metric:\n",
    "        best_val_metric = mean_val_iou\n",
    "        model.save_pretrained(f\"{best_model_dir}{CURR_TASK}/\")\n",
    "        counter=0\n",
    "    else:\n",
    "        counter+=1\n",
    "        if counter == PATIENCE:\n",
    "            print(\"Early stopping at epoch\",epoch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d222b70a-8636-4703-9b12-a013a891e6dd",
   "metadata": {},
   "source": [
    "## Test on A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "568ce989-44bf-4d9d-bb33-624970cd1571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate on test\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(f\"{best_model_dir}{CURR_TASK}/\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b53e4b9c-b403-4bbf-ba7b-60d92e0741fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loop: 100%|██████████| 14/14 [00:10<00:00,  1.36it/s, loss=136.1198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 8.2671, Test mIoU: 0.8541\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss/test_B</td><td>▁</td></tr><tr><td>Loss/train_B</td><td>█▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss/val_B</td><td>█▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mIoU/test_B</td><td>▁</td></tr><tr><td>mIoU/train_B</td><td>▁▁▃▃▄▅▅▆▆▇▇▇▇▇█████▇████████████████████</td></tr><tr><td>mIoU/val_B</td><td>▁▂▃▄▅▅▆▆▇█▆▇▇▇███▇█▆██▇█▇█▇█▇██▇▇█▇▇▇█▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss/test_B</td><td>8.26706</td></tr><tr><td>Loss/train_B</td><td>5.21622</td></tr><tr><td>Loss/val_B</td><td>7.89498</td></tr><tr><td>mIoU/test_B</td><td>0.85406</td></tr><tr><td>mIoU/train_B</td><td>0.96474</td></tr><tr><td>mIoU/val_B</td><td>0.82568</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">M2F-Swin-Tiny-Train_Cataract1k</strong> at: <a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/4t3o52ol' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original/runs/4t3o52ol</a><br/> View project at: <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240522_193014-4t3o52ol/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "test_running_loss = 0\n",
    "test_loader = tqdm(dataloaders[CURR_TASK][\"test\"], desc=\"Test loop\")\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        test_running_loss += current_loss\n",
    "        test_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor_B\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "        \n",
    "# After compute the batches that were added are deleted\n",
    "test_metrics_B = metric.compute(\n",
    "    num_labels=NUM_CLASSES, ignore_index=BG_VALUE_255, reduce_labels=False\n",
    ")\n",
    "mean_test_iou = test_metrics_B[\"mean_iou\"]\n",
    "final_test_loss = test_running_loss / len(dataloaders[CURR_TASK][\"test\"].dataset)\n",
    "wandb.log({\n",
    "    f\"Loss/test_{CURR_TASK}\": final_test_loss,\n",
    "    f\"mIoU/test_{CURR_TASK}\": mean_test_iou\n",
    "})\n",
    "print(f\"Test Loss: {final_test_loss:.4f}, Test mIoU: {mean_test_iou:.4f}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8fd5a7-3835-4b21-b4d4-377d6bedf2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
